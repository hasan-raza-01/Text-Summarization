{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from  zipfile import ZipFile\n",
    "\n",
    "# download\n",
    "source_uri=\"https://github.com/entbappy/Branching-tutorial/raw/master/summarizer-data.zip\"\n",
    "zip_file_path=\"outputs/data.zip\"\n",
    "urlretrieve(source_uri, zip_file_path)\n",
    "\n",
    "# extract\n",
    "data_dir=\"outputs/data\"\n",
    "with ZipFile(zip_file_path, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_summarization.utils import evaluate_summary\n",
    "reference_summary = \"Albert Einstein developed the theory of relativity, which changed our understanding of physics.\"\n",
    "\n",
    "generated_summary = \"Einstein introduced relativity, revolutionizing physics.\"\n",
    "rouge_scores = evaluate_summary(reference_summary, generated_summary)\n",
    "rouge_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_summarization.utils import evaluate_summary\n",
    "reference_summary = \"Albert Einstein developed the theory of relativity, which changed our understanding of physics.\"\n",
    "\n",
    "generated_summary = \"Albert Einstein developed the theory of relativity, which changed our understanding of physics.\"\n",
    "rouge_scores = evaluate_summary(reference_summary, generated_summary)\n",
    "rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "import torch\n",
    "\n",
    "src_text = [\n",
    "    \"\"\" PG&E stated it scheduled the blackouts in response to forecasts for high winds amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\"\"\n",
    "]\n",
    "\n",
    "model_name = \"google/pegasus-xsum\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "batch = tokenizer(src_text, truncation=True, padding=\"longest\", return_tensors=\"pt\").to(device)\n",
    "translated = model.generate(**batch)\n",
    "tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "assert (\n",
    "    tgt_text[0]\n",
    "    == \"California's largest electricity provider has turned off power to hundreds of thousands of customers.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "@dataclass\n",
    "class time_stamp:\n",
    "    time = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv.version\n",
    "import fastapi, uvicorn, dotenv, box, datasets, transformers, langchain_community, torch, rouge, accelerate, evaluate, tqdm\n",
    "\n",
    "print(f\"fastapi=={fastapi.__version__}\")\n",
    "print(f\"uvicorn=={uvicorn.__version__}\")\n",
    "print(f\"dotenv=={dotenv.version.__version__}\")\n",
    "print(f\"box=={box.__version__}\")\n",
    "print(f\"datasets=={datasets.__version__}\")\n",
    "print(f\"transformers=={transformers.__version__}\")\n",
    "print(f\"langchain_community=={langchain_community.__version__}\")\n",
    "print(f\"torch=={torch.__version__}\")\n",
    "print(f\"rouge=={rouge.__version__}\")\n",
    "print(f\"accelerate=={accelerate.__version__}\")\n",
    "print(f\"evaluate=={evaluate.__version__}\")\n",
    "print(f\"tqdm=={tqdm.__version__}\")\n",
    "%pip show langchain-huggingface\n",
    "%pip show rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_summarization.utils import load_json\n",
    "time_stamp = load_json(\"tokenizer_and_model_path.json\")[\"ARTIFACTS_PATH\"].split(os.sep)[-1]\n",
    "time_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"trainer_checkpoints/checkpoint-2\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "test_dataset = load_from_disk(\"less_records_artifacts/test\")\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from text_summarization.utils import load_json\n",
    "tokenizer_and_model_path = load_json(\"tokenizer_and_model_path.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not os.path.exists(tokenizer_and_model_path[\"TOKENIZER_PATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists(tokenizer_and_model_path[\"MODEL_PATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"artifacts/2025_02_26_16_42_27/model/training/finetuned_estimator/checkpoint-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(path)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
